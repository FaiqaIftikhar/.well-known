{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resNetSentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaiqaIftikhar/.well-known/blob/master/resNetSentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvD7s66RsaXN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0dnjVaj0xZa"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.optimizers import SGD\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7i9Xqz62Sc7"
      },
      "source": [
        "#emotion_data = pd.read_csv('/content/drive/My Drive/fer2013.csv')\n",
        "#print(emotion_data)\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZK6bEm_QZJr",
        "outputId": "55aec3d0-e777-4615-974a-8e197062de49"
      },
      "source": [
        "link='1E6PXNr_PBkvOImxb_YVR88wGm3SMRNs-'\n",
        "#fluff, id = link.split('=')\n",
        "#print (id)\n",
        "downloaded = drive.CreateFile({'id':link}) \n",
        "downloaded.GetContentFile('fer2013.csv')  \n",
        "emotion_data = pd.read_csv('fer2013.csv')\n",
        "print(emotion_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       emotion                                             pixels        Usage\n",
            "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n",
            "1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n",
            "2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n",
            "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n",
            "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n",
            "...        ...                                                ...          ...\n",
            "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
            "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
            "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
            "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
            "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n",
            "\n",
            "[35887 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PATgScEe2cab",
        "outputId": "6224f3ff-640a-4676-e95e-951bab9cd4e3"
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "for index, row in emotion_data.iterrows():\n",
        "    if row['Usage'] == 'Training':\n",
        "      k = row['pixels'].split(\" \")\n",
        "      X_train.append(np.array(k,'float32'))\n",
        "      y_train.append(row['emotion'])\n",
        "    elif row['Usage'] == 'PublicTest':\n",
        "      k = row['pixels'].split(\" \")\n",
        "      X_test.append(np.array(k,'float32'))\n",
        "      y_test.append(row['emotion'])\n",
        "  \n",
        "\n",
        "print(k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['61', '63', '59', '75', '151', '159', '166', '161', '143', '170', '127', '131', '184', '216', '222', '52', '70', '89', '83', '97', '93', '92', '88', '85', '89', '83', '85', '76', '67', '60', '60', '57', '31', '90', '136', '100', '122', '111', '71', '50', '92', '86', '88', '94', '82', '88', '81', '87', '60', '63', '54', '92', '158', '161', '162', '165', '138', '185', '199', '200', '212', '239', '81', '37', '92', '103', '100', '101', '104', '102', '99', '100', '101', '98', '97', '95', '91', '75', '63', '58', '54', '50', '156', '142', '119', '130', '84', '63', '74', '80', '82', '94', '92', '85', '83', '84', '58', '65', '53', '118', '161', '169', '154', '162', '163', '173', '197', '229', '210', '59', '33', '79', '98', '107', '108', '103', '104', '108', '109', '110', '113', '115', '118', '114', '109', '100', '85', '65', '61', '38', '118', '190', '132', '123', '104', '84', '56', '70', '78', '83', '89', '80', '91', '81', '59', '64', '57', '132', '153', '163', '175', '159', '192', '182', '197', '180', '36', '28', '35', '75', '94', '99', '103', '107', '112', '115', '120', '120', '124', '127', '129', '125', '123', '118', '108', '87', '69', '58', '43', '168', '164', '120', '114', '84', '74', '67', '74', '77', '91', '89', '78', '61', '60', '64', '61', '140', '146', '162', '159', '167', '196', '220', '204', '26', '35', '46', '14', '39', '86', '100', '104', '113', '120', '130', '136', '131', '134', '137', '138', '134', '130', '123', '113', '100', '78', '63', '44', '46', '165', '143', '123', '76', '94', '67', '68', '82', '81', '110', '66', '57', '59', '63', '63', '155', '159', '156', '165', '192', '214', '210', '65', '33', '53', '57', '71', '83', '86', '99', '109', '118', '126', '136', '140', '140', '141', '139', '135', '134', '125', '122', '111', '101', '85', '67', '56', '38', '49', '164', '139', '78', '77', '85', '64', '90', '73', '86', '74', '55', '61', '61', '70', '157', '158', '169', '179', '200', '176', '18', '25', '56', '65', '74', '76', '88', '98', '107', '116', '121', '131', '143', '142', '141', '144', '140', '138', '137', '131', '122', '114', '105', '92', '76', '58', '59', '24', '88', '165', '98', '58', '92', '69', '71', '77', '81', '86', '59', '62', '57', '81', '167', '161', '169', '180', '214', '83', '8', '51', '56', '70', '73', '79', '94', '115', '120', '120', '127', '138', '146', '152', '147', '149', '145', '143', '141', '133', '127', '118', '108', '97', '78', '71', '62', '49', '38', '147', '110', '73', '90', '73', '65', '76', '74', '78', '88', '62', '55', '93', '171', '162', '171', '195', '199', '35', '33', '49', '57', '66', '71', '87', '104', '124', '126', '131', '139', '146', '153', '154', '149', '154', '149', '141', '148', '137', '132', '125', '110', '99', '90', '80', '69', '59', '33', '126', '121', '68', '88', '78', '49', '71', '78', '79', '83', '63', '53', '99', '184', '159', '175', '207', '150', '10', '48', '51', '64', '67', '77', '97', '109', '125', '138', '145', '147', '156', '155', '158', '154', '156', '154', '148', '152', '142', '133', '120', '105', '97', '96', '96', '86', '72', '41', '86', '130', '70', '84', '83', '47', '79', '71', '74', '73', '65', '52', '105', '183', '154', '183', '207', '67', '11', '52', '60', '72', '71', '85', '96', '117', '136', '152', '155', '157', '160', '161', '157', '158', '170', '162', '158', '159', '140', '131', '122', '119', '124', '124', '120', '107', '86', '56', '65', '128', '78', '88', '81', '59', '66', '62', '79', '94', '65', '54', '102', '182', '165', '192', '177', '17', '29', '53', '66', '66', '81', '92', '104', '122', '141', '148', '164', '159', '156', '162', '158', '158', '168', '162', '150', '155', '132', '116', '131', '138', '138', '127', '117', '118', '111', '83', '58', '119', '82', '76', '79', '88', '51', '70', '79', '81', '65', '58', '97', '175', '173', '196', '123', '3', '45', '57', '68', '92', '101', '104', '111', '126', '140', '154', '160', '159', '147', '155', '148', '149', '161', '149', '139', '132', '119', '124', '111', '87', '78', '62', '55', '51', '60', '68', '53', '105', '87', '81', '84', '88', '63', '65', '76', '78', '63', '56', '93', '176', '170', '194', '87', '4', '48', '54', '89', '91', '88', '105', '111', '116', '124', '139', '144', '144', '134', '140', '138', '131', '138', '130', '113', '78', '78', '63', '40', '26', '25', '27', '29', '30', '31', '35', '28', '98', '91', '102', '92', '82', '74', '54', '77', '79', '64', '56', '92', '175', '173', '179', '31', '23', '47', '62', '62', '34', '37', '51', '57', '59', '74', '96', '105', '117', '119', '135', '127', '122', '103', '87', '64', '55', '38', '16', '21', '31', '40', '48', '63', '71', '62', '58', '37', '94', '96', '99', '95', '93', '71', '59', '78', '83', '62', '57', '93', '174', '182', '155', '0', '34', '52', '41', '19', '15', '11', '11', '18', '21', '36', '51', '54', '84', '101', '125', '148', '115', '88', '63', '42', '32', '30', '32', '40', '57', '74', '86', '90', '81', '69', '62', '41', '118', '101', '98', '105', '103', '75', '66', '58', '79', '65', '59', '93', '172', '198', '146', '0', '36', '44', '22', '28', '28', '42', '46', '49', '40', '32', '37', '39', '59', '81', '119', '146', '121', '94', '67', '49', '42', '38', '26', '26', '52', '53', '44', '37', '29', '32', '29', '16', '114', '149', '103', '104', '91', '75', '68', '49', '60', '67', '59', '95', '167', '200', '125', '0', '40', '40', '38', '52', '73', '89', '81', '68', '50', '43', '44', '50', '59', '83', '130', '136', '126', '114', '85', '63', '47', '26', '14', '47', '41', '40', '20', '33', '57', '20', '12', '11', '39', '151', '122', '95', '99', '73', '72', '56', '67', '66', '55', '110', '174', '196', '97', '0', '46', '52', '54', '56', '45', '30', '41', '39', '41', '38', '28', '32', '58', '91', '130', '160', '147', '116', '83', '70', '42', '25', '20', '91', '67', '8', '11', '81', '99', '43', '23', '37', '29', '95', '135', '90', '92', '78', '77', '57', '65', '67', '56', '108', '183', '193', '65', '3', '55', '54', '42', '14', '11', '23', '17', '20', '47', '135', '75', '40', '42', '87', '128', '198', '179', '121', '87', '77', '43', '47', '49', '43', '58', '55', '61', '65', '43', '49', '63', '73', '56', '66', '133', '85', '96', '86', '61', '54', '47', '68', '56', '112', '191', '205', '46', '24', '57', '52', '37', '21', '18', '51', '30', '17', '64', '96', '60', '60', '50', '89', '136', '209', '185', '124', '89', '86', '51', '49', '68', '69', '65', '60', '61', '62', '73', '85', '92', '99', '91', '57', '111', '99', '101', '76', '56', '52', '45', '69', '55', '121', '199', '207', '60', '38', '62', '68', '77', '70', '44', '34', '48', '62', '65', '48', '50', '73', '68', '108', '146', '213', '167', '115', '98', '98', '80', '67', '57', '69', '92', '97', '102', '108', '115', '115', '111', '114', '114', '75', '109', '133', '91', '80', '68', '69', '51', '66', '58', '105', '195', '192', '60', '43', '69', '79', '94', '87', '70', '61', '55', '58', '65', '74', '86', '77', '96', '128', '160', '220', '153', '111', '108', '114', '99', '92', '103', '85', '85', '103', '117', '125', '131', '139', '142', '139', '119', '98', '85', '117', '88', '89', '70', '70', '42', '65', '58', '93', '191', '190', '60', '42', '72', '84', '94', '96', '94', '98', '98', '103', '106', '106', '89', '96', '133', '144', '176', '211', '151', '115', '100', '105', '98', '96', '122', '142', '137', '134', '134', '146', '150', '152', '148', '135', '118', '97', '76', '117', '97', '85', '69', '68', '43', '65', '63', '78', '185', '201', '78', '38', '73', '90', '102', '106', '111', '112', '117', '113', '111', '102', '112', '134', '141', '146', '170', '171', '145', '113', '87', '76', '90', '93', '118', '149', '159', '161', '156', '152', '146', '136', '126', '113', '94', '93', '62', '106', '89', '81', '79', '59', '47', '64', '68', '61', '170', '206', '99', '35', '75', '90', '100', '102', '110', '116', '112', '110', '117', '135', '158', '145', '147', '142', '165', '168', '139', '111', '80', '72', '75', '88', '110', '142', '159', '166', '162', '154', '142', '121', '120', '100', '87', '78', '59', '72', '92', '81', '39', '26', '26', '67', '70', '56', '153', '203', '128', '40', '73', '84', '97', '95', '93', '98', '105', '117', '143', '165', '159', '150', '144', '138', '195', '192', '143', '108', '72', '61', '68', '66', '110', '130', '156', '160', '158', '151', '137', '125', '104', '89', '81', '72', '52', '72', '97', '37', '30', '44', '37', '66', '70', '55', '121', '200', '151', '43', '67', '81', '89', '88', '89', '100', '119', '139', '162', '169', '166', '152', '130', '144', '198', '188', '156', '91', '69', '68', '83', '65', '93', '125', '144', '144', '145', '137', '126', '107', '96', '84', '76', '68', '54', '48', '46', '51', '59', '55', '37', '65', '69', '59', '104', '196', '178', '61', '55', '70', '73', '73', '84', '108', '130', '149', '158', '165', '162', '146', '149', '136', '173', '162', '130', '71', '56', '88', '110', '64', '83', '118', '133', '138', '133', '126', '113', '100', '84', '78', '71', '57', '48', '26', '67', '59', '36', '17', '7', '65', '67', '65', '83', '174', '188', '95', '42', '62', '72', '72', '84', '104', '129', '143', '154', '160', '159', '153', '138', '72', '106', '131', '100', '42', '0', '19', '62', '52', '93', '123', '124', '129', '124', '121', '107', '89', '80', '73', '64', '55', '43', '33', '50', '27', '11', '4', '6', '64', '67', '68', '71', '170', '191', '123', '40', '65', '68', '73', '78', '98', '120', '137', '156', '152', '160', '172', '108', '40', '45', '93', '71', '32', '59', '76', '55', '77', '105', '113', '120', '118', '127', '124', '103', '84', '74', '72', '66', '55', '55', '39', '29', '5', '6', '14', '18', '63', '65', '67', '65', '169', '189', '153', '43', '57', '69', '70', '75', '100', '114', '132', '145', '157', '165', '181', '165', '116', '118', '94', '66', '75', '86', '79', '90', '100', '102', '109', '114', '114', '112', '114', '104', '94', '82', '65', '59', '44', '61', '24', '15', '6', '28', '37', '26', '63', '65', '69', '57', '152', '195', '184', '54', '53', '64', '67', '76', '93', '105', '120', '149', '156', '168', '175', '182', '163', '127', '114', '107', '102', '87', '85', '95', '102', '101', '98', '104', '110', '102', '108', '101', '86', '86', '63', '47', '37', '48', '18', '7', '18', '51', '48', '25', '63', '65', '71', '55', '137', '191', '174', '68', '49', '61', '64', '71', '84', '100', '122', '143', '151', '168', '173', '176', '158', '142', '123', '105', '110', '96', '86', '95', '102', '94', '86', '90', '102', '94', '88', '91', '82', '73', '64', '42', '18', '26', '12', '14', '54', '36', '34', '34', '64', '66', '70', '56', '119', '198', '178', '98', '45', '62', '65', '71', '86', '112', '131', '136', '148', '160', '161', '158', '151', '150', '144', '125', '120', '89', '79', '85', '93', '86', '81', '80', '84', '79', '71', '78', '80', '69', '36', '24', '15', '18', '11', '35', '74', '43', '61', '43', '65', '67', '69', '60', '99', '205', '186', '119', '43', '59', '69', '68', '89', '113', '127', '128', '137', '137', '136', '140', '146', '112', '95', '112', '74', '56', '55', '44', '49', '56', '68', '69', '70', '68', '61', '73', '67', '53', '14', '31', '40', '42', '38', '65', '75', '68', '49', '48', '66', '67', '70', '64', '86', '199', '197', '137', '40', '53', '66', '70', '90', '105', '116', '116', '123', '131', '122', '112', '74', '49', '58', '50', '40', '24', '18', '16', '20', '22', '24', '42', '52', '60', '60', '64', '59', '37', '9', '38', '43', '27', '73', '91', '68', '117', '78', '41', '66', '68', '68', '67', '76', '198', '188', '153', '71', '47', '64', '73', '83', '102', '108', '102', '108', '101', '60', '29', '20', '48', '47', '48', '57', '55', '79', '92', '78', '64', '68', '72', '43', '44', '57', '66', '55', '32', '24', '45', '21', '44', '109', '69', '120', '108', '87', '68', '65', '67', '68', '70', '61', '177', '186', '175', '97', '48', '59', '69', '76', '94', '105', '104', '100', '67', '68', '77', '110', '163', '173', '164', '152', '150', '135', '92', '66', '65', '62', '52', '39', '42', '55', '65', '44', '23', '30', '45', '16', '80', '80', '98', '115', '66', '67', '97', '64', '66', '66', '71', '56', '152', '193', '184', '122', '49', '54', '67', '69', '84', '105', '112', '93', '79', '113', '138', '125', '105', '117', '124', '113', '119', '86', '64', '67', '51', '46', '49', '48', '47', '49', '51', '37', '11', '32', '33', '23', '69', '93', '116', '104', '114', '82', '120', '62', '63', '65', '68', '57', '120', '200', '173', '154', '71', '58', '61', '68', '82', '103', '112', '98', '92', '93', '87', '74', '72', '77', '83', '73', '59', '54', '60', '63', '51', '49', '47', '49', '46', '44', '38', '31', '22', '44', '31', '43', '92', '106', '118', '157', '118', '68', '68', '60', '61', '63', '66', '56', '96', '200', '168', '176', '97', '56', '56', '63', '70', '91', '99', '100', '112', '110', '96', '87', '79', '66', '48', '44', '49', '56', '63', '58', '47', '47', '42', '47', '50', '43', '38', '28', '21', '28', '29', '79', '79', '115', '157', '148', '44', '101', '83', '58', '60', '60', '64', '60', '78', '191', '180', '187', '90', '75', '55', '57', '63', '76', '87', '95', '104', '107', '92', '84', '84', '74', '71', '76', '89', '90', '78', '74', '62', '52', '46', '49', '53', '43', '34', '27', '21', '21', '34', '84', '83', '149', '142', '43', '75', '128', '63', '57', '60', '62', '63', '62', '62', '175', '187', '183', '78', '91', '83', '52', '56', '62', '80', '88', '98', '101', '97', '99', '105', '100', '116', '133', '130', '121', '98', '85', '76', '66', '53', '49', '43', '36', '31', '24', '19', '16', '37', '76', '106', '124', '65', '131', '102', '103', '129', '58', '60', '61', '62', '64', '54', '149', '185', '176', '96', '91', '84', '80', '49', '60', '72', '84', '93', '100', '111', '126', '126', '140', '153', '134', '119', '121', '111', '110', '86', '68', '57', '48', '44', '35', '25', '21', '22', '17', '45', '77', '80', '71', '132', '110', '137', '115', '156', '59', '60', '60', '62', '64', '49', '118', '186', '184', '130', '79', '74', '86', '66', '55', '63', '77', '87', '99', '119', '135', '141', '157', '152', '134', '109', '114', '116', '98', '77', '65', '53', '49', '41', '32', '21', '17', '25', '26', '44', '78', '109', '100', '126', '132', '124', '120', '197', '58', '60', '59', '61', '62', '50', '92', '180', '187', '158', '83', '74', '57', '58', '59', '58', '63', '81', '101', '121', '136', '139', '141', '135', '121', '103', '101', '101', '87', '71', '63', '53', '46', '31', '24', '24', '23', '23', '39', '26', '87', '149', '128', '162', '134', '101', '152', '185', '56', '58', '58', '60', '59', '51', '74', '182', '190', '180', '86', '74', '57', '49', '53', '69', '47', '61', '85', '113', '127', '127', '120', '114', '103', '86', '91', '101', '88', '62', '59', '52', '40', '25', '21', '22', '24', '13', '36', '39', '92', '139', '143', '162', '119', '113', '165', '180']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMK340OF2k8W"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "width, height = 48, 48\n",
        "\n",
        "\n",
        "X_train = np.array(X_train,'float32')\n",
        "y_train = np.array(y_train,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "y_test = np.array(y_test,'float32')\n",
        "\n",
        "y_train= np_utils.to_categorical(y_train, num_classes=7)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes=7)\n",
        "\n",
        "#cannot produce\n",
        "#normalizing data between oand 1\n",
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwNKZpBp2wFW"
      },
      "source": [
        "stride = 1\n",
        "CHANNEL_AXIS = 3\n",
        "\n",
        "def res_layer(x ,filters,pooling = False,dropout = 0.0):\n",
        "    temp = x\n",
        "    temp = Conv2D(filters,(3,3),strides = stride,padding = \"same\")(temp)\n",
        "    temp = BatchNormalization(axis = CHANNEL_AXIS)(temp)\n",
        "    temp = Activation(\"relu\")(temp)\n",
        "    temp = Conv2D(filters,(3,3),strides = stride,padding = \"same\")(temp)\n",
        "\n",
        "    x = add([temp,Conv2D(filters,(3,3),strides = stride,padding = \"same\")(x)])\n",
        "    if pooling:\n",
        "        x = MaxPooling2D((2,2))(x)\n",
        "    if dropout != 0.0:\n",
        "        x = Dropout(dropout)(x)\n",
        "    x = BatchNormalization(axis = CHANNEL_AXIS)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcKEZvxE27g_",
        "outputId": "8e93c8b5-6b9d-4eea-fa28-6a4955359f2a"
      },
      "source": [
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import add\n",
        "from keras.layers import Input,Activation\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "kernel_size = (3, 3)\n",
        "input_shape=X_train.shape[1:]\n",
        "inp = Input(shape=input_shape)\n",
        "x = inp\n",
        "x = Conv2D(16,(3,3),strides = stride,padding = \"same\")(x)\n",
        "x = BatchNormalization(axis = CHANNEL_AXIS)(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = res_layer(x,32,dropout = 0.2)\n",
        "x = res_layer(x,32,dropout = 0.3)\n",
        "x = res_layer(x,32,dropout = 0.4,pooling = True)\n",
        "x = res_layer(x,64,dropout = 0.2)\n",
        "x = res_layer(x,64,dropout = 0.2,pooling = True)\n",
        "x = res_layer(x,256,dropout = 0.4)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(4096,activation = \"relu\")(x)\n",
        "x = Dropout(0.23)(x)\n",
        "x = Dense(7,activation = \"softmax\")(x)\n",
        "\n",
        "resnet_model = Model(inp,x,name = \"Resnet\")\n",
        "resnet_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Resnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 48, 48, 16)   160         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 48, 48, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 48, 48, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 48, 48, 32)   4640        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 48, 48, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 48, 48, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 48, 48, 32)   9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 48, 48, 32)   4640        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 48, 48, 32)   0           conv2d_2[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 48, 48, 32)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 48, 48, 32)   128         dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 48, 48, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 48, 48, 32)   9248        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 48, 48, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 48, 48, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 48, 48, 32)   9248        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 48, 48, 32)   9248        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 48, 48, 32)   0           conv2d_5[0][0]                   \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 48, 48, 32)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 48, 48, 32)   128         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 48, 48, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 48, 48, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 48, 48, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 48, 48, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 48, 48, 32)   9248        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 48, 48, 32)   9248        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 48, 48, 32)   0           conv2d_8[0][0]                   \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 24, 24, 32)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 24, 24, 32)   0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 24, 24, 32)   128         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 24, 24, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 24, 24, 64)   18496       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 24, 24, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 24, 24, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 24, 24, 64)   36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 24, 24, 64)   18496       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 24, 24, 64)   0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 24, 24, 64)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 24, 24, 64)   256         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 24, 24, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 24, 24, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 24, 24, 64)   256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 24, 24, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 24, 24, 64)   36928       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 24, 24, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 24, 24, 64)   0           conv2d_14[0][0]                  \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 64)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 12, 12, 64)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 12, 12, 64)   256         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 12, 12, 64)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 12, 12, 256)  147712      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 12, 12, 256)  1024        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 12, 12, 256)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 12, 12, 256)  590080      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 12, 12, 256)  147712      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 12, 12, 256)  0           conv2d_17[0][0]                  \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 12, 12, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 12, 12, 256)  1024        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 12, 12, 256)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 36864)        0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 36864)        0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4096)         150999040   dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 4096)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 7)            28679       dropout_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 152,176,007\n",
            "Trainable params: 152,174,055\n",
            "Non-trainable params: 1,952\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjwDaaaf3y4j"
      },
      "source": [
        "resnet_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZvqSeXw39cP",
        "outputId": "b202ad9a-27a0-472b-b5b2-4bc73f8ff97b"
      },
      "source": [
        "resnet_model.fit(X_train,y_train,batch_size=32,epochs=30,verbose=1,validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "898/898 [==============================] - 67s 66ms/step - loss: 6.2667 - accuracy: 0.2411 - val_loss: 1.7550 - val_accuracy: 0.2940\n",
            "Epoch 2/30\n",
            "898/898 [==============================] - 59s 65ms/step - loss: 1.7537 - accuracy: 0.2835 - val_loss: 1.6283 - val_accuracy: 0.3558\n",
            "Epoch 3/30\n",
            "898/898 [==============================] - 59s 66ms/step - loss: 1.6237 - accuracy: 0.3536 - val_loss: 1.4810 - val_accuracy: 0.4160\n",
            "Epoch 4/30\n",
            "898/898 [==============================] - 59s 66ms/step - loss: 1.5284 - accuracy: 0.3985 - val_loss: 1.5085 - val_accuracy: 0.4146\n",
            "Epoch 5/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.4619 - accuracy: 0.4340 - val_loss: 1.3730 - val_accuracy: 0.4748\n",
            "Epoch 6/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.4083 - accuracy: 0.4507 - val_loss: 1.4018 - val_accuracy: 0.4717\n",
            "Epoch 7/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.3560 - accuracy: 0.4768 - val_loss: 1.3041 - val_accuracy: 0.4985\n",
            "Epoch 8/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.3153 - accuracy: 0.4912 - val_loss: 1.2656 - val_accuracy: 0.5300\n",
            "Epoch 9/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.2894 - accuracy: 0.5014 - val_loss: 1.2274 - val_accuracy: 0.5177\n",
            "Epoch 10/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.2713 - accuracy: 0.5105 - val_loss: 1.2418 - val_accuracy: 0.5213\n",
            "Epoch 11/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.2218 - accuracy: 0.5320 - val_loss: 1.2253 - val_accuracy: 0.5408\n",
            "Epoch 12/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.2014 - accuracy: 0.5445 - val_loss: 1.1920 - val_accuracy: 0.5394\n",
            "Epoch 13/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.1645 - accuracy: 0.5552 - val_loss: 1.2130 - val_accuracy: 0.5339\n",
            "Epoch 14/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.1501 - accuracy: 0.5621 - val_loss: 1.1458 - val_accuracy: 0.5651\n",
            "Epoch 15/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.1220 - accuracy: 0.5713 - val_loss: 1.1954 - val_accuracy: 0.5659\n",
            "Epoch 16/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.0625 - accuracy: 0.5956 - val_loss: 1.1968 - val_accuracy: 0.5570\n",
            "Epoch 17/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.0366 - accuracy: 0.6090 - val_loss: 1.1856 - val_accuracy: 0.5662\n",
            "Epoch 18/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 1.0045 - accuracy: 0.6188 - val_loss: 1.2107 - val_accuracy: 0.5670\n",
            "Epoch 19/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 0.9670 - accuracy: 0.6283 - val_loss: 1.1440 - val_accuracy: 0.5776\n",
            "Epoch 20/30\n",
            "898/898 [==============================] - 61s 68ms/step - loss: 0.9222 - accuracy: 0.6510 - val_loss: 1.1330 - val_accuracy: 0.5837\n",
            "Epoch 21/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 0.8741 - accuracy: 0.6711 - val_loss: 1.1142 - val_accuracy: 0.5940\n",
            "Epoch 22/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 0.8290 - accuracy: 0.6909 - val_loss: 1.1284 - val_accuracy: 0.5932\n",
            "Epoch 23/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 0.7759 - accuracy: 0.7087 - val_loss: 1.1589 - val_accuracy: 0.5929\n",
            "Epoch 24/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 0.7451 - accuracy: 0.7208 - val_loss: 1.0916 - val_accuracy: 0.6180\n",
            "Epoch 25/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 0.6745 - accuracy: 0.7512 - val_loss: 1.1681 - val_accuracy: 0.6032\n",
            "Epoch 26/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 0.6304 - accuracy: 0.7643 - val_loss: 1.2286 - val_accuracy: 0.5974\n",
            "Epoch 27/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 0.5955 - accuracy: 0.7785 - val_loss: 1.2712 - val_accuracy: 0.5924\n",
            "Epoch 28/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 0.5391 - accuracy: 0.8043 - val_loss: 1.2040 - val_accuracy: 0.6071\n",
            "Epoch 29/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 0.4953 - accuracy: 0.8178 - val_loss: 1.3521 - val_accuracy: 0.6105\n",
            "Epoch 30/30\n",
            "898/898 [==============================] - 60s 67ms/step - loss: 0.4696 - accuracy: 0.8322 - val_loss: 1.3410 - val_accuracy: 0.6191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f91f405a5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQTRtJhZ2BYS",
        "outputId": "482582c8-f91b-4567-81b3-414b03348076"
      },
      "source": [
        "# predict probabilities for test set\n",
        "yhat_probs = resnet_model.predict(X_test, verbose=0)\n",
        "# predict crisp classes for test set\n",
        "yhat_classes = resnet_model.predict(X_test, verbose=0)\n",
        "# reduce to 1d array\n",
        "#yhat_probs = yhat_probs[:, 0]\n",
        "#yhat_classes = yhat_classes[:, 0]\n",
        "#y_test = y_test[:, 0]\n",
        "yhat_probs = yhat_probs[:, 0]\n",
        "yhat_classes = yhat_classes[:, 0]\n",
        "print(y_test)\n",
        "print(yhat_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. ... 0. 0. 0.]\n",
            "[0.25846094 0.02656565 0.6691495  ... 0.00263612 0.79040784 0.15040687]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDiXAe6UQovW",
        "outputId": "b63cac49-1b21-4315-8553-0777d74f895f"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(y_test, yhat_classes.round())\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, yhat_classes.round(),pos_label='positive',average='macro')\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test, yhat_classes.round(),pos_label='positive',average='macro')\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, yhat_classes.round(),pos_label='positive',average='macro')\n",
        "print('F1 score: %f' % f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.886598\n",
            "Precision: 0.750574\n",
            "Recall: 0.715384\n",
            "F1 score: 0.730892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}